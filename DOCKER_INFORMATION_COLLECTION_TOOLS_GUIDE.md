# ä½¿ç”¨Dockeræ­å»ºä¿¡æ¯æ”¶é›†æ•´ç†å·¥å…·å®Œæ•´æŒ‡å—

## ç›®å½•
1. [ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ](#ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ)
2. [æ ¸å¿ƒå·¥å…·ä»‹ç»](#æ ¸å¿ƒå·¥å…·ä»‹ç»)
3. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
4. [é€æ­¥éƒ¨ç½²æŒ‡å—](#é€æ­¥éƒ¨ç½²æŒ‡å—)
5. [é«˜çº§é…ç½®](#é«˜çº§é…ç½®)
6. [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
7. [ç»´æŠ¤å’Œå¤‡ä»½](#ç»´æŠ¤å’Œå¤‡ä»½)
8. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### ä¿¡æ¯æ”¶é›†æ•´ç†ç³»ç»Ÿç»„ä»¶å›¾
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   åå‘ä»£ç†      â”‚
                    â”‚   (Nginx)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚             â”‚             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ RSSèšåˆå·¥å…·   â”‚ â”‚çŸ¥è¯†ç®¡ç† â”‚ â”‚ æ–‡æ¡£æœåŠ¡   â”‚
        â”‚ (FreshRSS)   â”‚ â”‚(Outline)â”‚ â”‚(BookStack) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚             â”‚             â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     æ•°æ®åº“      â”‚
                    â”‚ (PostgreSQL)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
- **ä¿¡æ¯æ”¶é›†å±‚**: RSSèšåˆã€ç½‘é¡µå‰ªè—ã€æ–‡æ¡£å¯¼å…¥
- **å­˜å‚¨å¤„ç†å±‚**: æ•°æ®åº“ã€æ–‡ä»¶å­˜å‚¨ã€å…¨æ–‡æœç´¢
- **ç»„ç»‡ç®¡ç†å±‚**: åˆ†ç±»æ ‡ç­¾ã€çŸ¥è¯†å›¾è°±ã€ç‰ˆæœ¬æ§åˆ¶
- **å±•ç¤ºè¾“å‡ºå±‚**: Webç•Œé¢ã€APIæ¥å£ã€å¯¼å‡ºåŠŸèƒ½

## æ ¸å¿ƒå·¥å…·ä»‹ç»

### 1. FreshRSS - RSSè®¢é˜…èšåˆå™¨
**åŠŸèƒ½ç‰¹ç‚¹**:
- æ”¯æŒRSS/Atom/JSON Feed
- å…¨æ–‡æœç´¢å’Œè¿‡æ»¤
- æ ‡ç­¾åˆ†ç±»å’Œæ”¶è—
- ç§»åŠ¨ç«¯é€‚é…

**é€‚ç”¨åœºæ™¯**:
- æ–°é—»èµ„è®¯èšåˆ
- åšå®¢æ–‡ç« è¿½è¸ª
- æŠ€æœ¯æ›´æ–°ç›‘æ§

### 2. Outline - ç°ä»£åŒ–çŸ¥è¯†åº“
**åŠŸèƒ½ç‰¹ç‚¹**:
- å®æ—¶åä½œç¼–è¾‘
- Markdownæ”¯æŒ
- å±‚çº§ç»“æ„ç»„ç»‡
- å¼ºå¤§çš„æœç´¢åŠŸèƒ½

**é€‚ç”¨åœºæ™¯**:
- å›¢é˜ŸçŸ¥è¯†åº“
- ä¸ªäººç¬”è®°ç³»ç»Ÿ
- é¡¹ç›®æ–‡æ¡£ç®¡ç†

### 3. BookStack - è‡ªæ‰˜ç®¡Wikiå¹³å°
**åŠŸèƒ½ç‰¹ç‚¹**:
- ä¹¦ç±-ç« èŠ‚-é¡µé¢ç»“æ„
- ç”¨æˆ·æƒé™ç®¡ç†
- ä¸°å¯Œçš„ç¼–è¾‘å™¨
- å¯¼å‡ºå¤šç§æ ¼å¼

**é€‚ç”¨åœºæ™¯**:
- æŠ€æœ¯æ–‡æ¡£
- å­¦ä¹ ç¬”è®°
- æ“ä½œæ‰‹å†Œ

### 4. Wallabag - ç¨åé˜…è¯»æœåŠ¡
**åŠŸèƒ½ç‰¹ç‚¹**:
- ç¦»çº¿é˜…è¯»æ”¯æŒ
- å…¨æ–‡æå–
- æ ‡ç­¾å’Œåˆ†ç±»
- å¤šç«¯åŒæ­¥

**é€‚ç”¨åœºæ™¯**:
- æ–‡ç« æ”¶è—
- ç¦»çº¿é˜…è¯»
- å†…å®¹æ•´ç†

### 5. Elasticsearch + Kibana - æœç´¢åˆ†æ
**åŠŸèƒ½ç‰¹ç‚¹**:
- å…¨æ–‡æœç´¢å¼•æ“
- æ•°æ®å¯è§†åŒ–
- å®æ—¶åˆ†æ
- RESTful API

**é€‚ç”¨åœºæ™¯**:
- æµ·é‡æ–‡æ¡£æœç´¢
- æ•°æ®åˆ†æå±•ç¤º
- å†…å®¹æŒ–æ˜

## ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux/Windows/macOS
- **å†…å­˜**: æœ€ä½4GBï¼Œæ¨è8GB+
- **å­˜å‚¨**: 50GB+å¯ç”¨ç©ºé—´
- **Dockerç‰ˆæœ¬**: 20.10+
- **Docker Composeç‰ˆæœ¬**: 2.0+

### ç›®å½•ç»“æ„å‡†å¤‡
```bash
mkdir -p ~/info-collection-system/{
  config,
  data/{postgres,elasticsearch,redis,uploads},
  logs,
  backups,
  docker-compose-files
}

cd ~/info-collection-system
```

## é€æ­¥éƒ¨ç½²æŒ‡å—

### ç¬¬ä¸€æ­¥ï¼šåŸºç¡€æœåŠ¡éƒ¨ç½²

#### 1.1 åˆ›å»ºç½‘ç»œå’Œå­˜å‚¨å·
```bash
# åˆ›å»ºDockerç½‘ç»œ
docker network create info-net

# åˆ›å»ºå­˜å‚¨å·
docker volume create postgres_data
docker volume create elasticsearch_data
docker volume create redis_data
```

#### 1.2 éƒ¨ç½²åŸºç¡€æœåŠ¡æ ˆ
åˆ›å»º `docker-compose.base.yml`:
```yaml
version: '3.8'

services:
  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: info-postgres
    environment:
      POSTGRES_DB: info_db
      POSTGRES_USER: info_user
      POSTGRES_PASSWORD: your_secure_password
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./config/postgres:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - info-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U info_user -d info_db"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: info-redis
    command: redis-server --appendonly yes --requirepass your_redis_password
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - info-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Elasticsearchæœç´¢å¼•æ“
  elasticsearch:
    image: elasticsearch:8.11.0
    container_name: info-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx2g"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - info-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  redis_data:
  elasticsearch_data:

networks:
  info-net:
    external: true
```

å¯åŠ¨åŸºç¡€æœåŠ¡:
```bash
docker-compose -f docker-compose.base.yml up -d
```

### ç¬¬äºŒæ­¥ï¼šä¿¡æ¯æ”¶é›†å·¥å…·éƒ¨ç½²

#### 2.1 FreshRSS RSSèšåˆå™¨
åˆ›å»º `docker-compose.freshrss.yml`:
```yaml
version: '3.8'

services:
  freshrss:
    image: freshrss/freshrss:latest
    container_name: info-freshrss
    environment:
      CRON_MIN: '*/15'  # æ¯15åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
      TZ: Asia/Shanghai
    volumes:
      - ./data/freshrss:/var/www/FreshRSS/data
      - ./config/freshrss:/var/www/FreshRSS/data/users/_/config
    ports:
      - "8080:80"
    networks:
      - info-net
    depends_on:
      - postgres
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.freshrss.rule=Host(`rss.localhost`)"
      - "traefik.http.services.freshrss.loadbalancer.server.port=80"

networks:
  info-net:
    external: true
```

#### 2.2 OutlineçŸ¥è¯†åº“
åˆ›å»º `docker-compose.outline.yml`:
```yaml
version: '3.8'

services:
  outline:
    image: outlinewiki/outline:latest
    container_name: info-outline
    environment:
      SECRET_KEY: your_secret_key_32_chars_long
      UTILS_SECRET: your_utils_secret_32_chars_long
      DATABASE_URL: postgres://info_user:your_secure_password@postgres:5432/outline_db
      REDIS_URL: redis://:your_redis_password@redis:6379
      URL: http://localhost:8081
      PORT: 3000
      
      # æ–‡ä»¶å­˜å‚¨é…ç½®
      FILE_STORAGE: local
      FILE_STORAGE_LOCAL_ROOT_DIR: /var/lib/outline/data
      FILE_STORAGE_UPLOAD_MAX_SIZE: 26214400
      
      # æœç´¢é…ç½®
      ENABLE_UPDATES: false
      DEBUG: cache,presenters,events
      
      # å¯é€‰ï¼šSlacké›†æˆ
      # SLACK_CLIENT_ID: your_slack_client_id
      # SLACK_CLIENT_SECRET: your_slack_client_secret
    volumes:
      - ./data/outline:/var/lib/outline/data
    ports:
      - "8081:3000"
    networks:
      - info-net
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

networks:
  info-net:
    external: true
```

#### 2.3 BookStackæ–‡æ¡£å¹³å°
åˆ›å»º `docker-compose.bookstack.yml`:
```yaml
version: '3.8'

services:
  bookstack:
    image: lscr.io/linuxserver/bookstack:latest
    container_name: info-bookstack
    environment:
      PUID: 1000
      PGID: 1000
      APP_URL: http://localhost:8082
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: info_user
      DB_PASS: your_secure_password
      DB_DATABASE: bookstack_db
      MAIL_DRIVER: smtp
      MAIL_HOST: smtp.gmail.com
      MAIL_PORT: 587
      MAIL_ENCRYPTION: tls
      MAIL_USERNAME: your_email@gmail.com
      MAIL_PASSWORD: your_email_password
      MAIL_FROM_NAME: BookStack
    volumes:
      - ./data/bookstack:/config
    ports:
      - "8082:80"
    networks:
      - info-net
    depends_on:
      - postgres
    restart: unless-stopped

networks:
  info-net:
    external: true
```

#### 2.4 Wallabagç¨åé˜…è¯»
åˆ›å»º `docker-compose.wallabag.yml`:
```yaml
version: '3.8'

services:
  wallabag:
    image: wallabag/wallabag:latest
    container_name: info-wallabag
    environment:
      SYMFONY__ENV__DATABASE_DRIVER: pdo_pgsql
      SYMFONY__ENV__DATABASE_HOST: postgres
      SYMFONY__ENV__DATABASE_PORT: 5432
      SYMFONY__ENV__DATABASE_NAME: wallabag_db
      SYMFONY__ENV__DATABASE_USER: info_user
      SYMFONY__ENV__DATABASE_PASSWORD: your_secure_password
      SYMFONY__ENV__DATABASE_CHARSET: utf8
      SYMFONY__ENV__SECRET: your_wallabag_secret_key
      SYMFONY__ENV__DOMAIN_NAME: http://localhost:8083
      SYMFONY__ENV__MAILER_DSN: smtp://localhost
      SYMFONY__ENV__FROM_EMAIL: wallabag@localhost
    volumes:
      - ./data/wallabag/images:/var/www/wallabag/web/assets/images
      - ./data/wallabag/data:/var/www/wallabag/data
    ports:
      - "8083:80"
    networks:
      - info-net
    depends_on:
      - postgres
    restart: unless-stopped

networks:
  info-net:
    external: true
```

### ç¬¬ä¸‰æ­¥ï¼šåˆ†æå’Œå¯è§†åŒ–å·¥å…·

#### 3.1 Kibanaæ•°æ®å¯è§†åŒ–
åˆ›å»º `docker-compose.kibana.yml`:
```yaml
version: '3.8'

services:
  kibana:
    image: kibana:8.11.0
    container_name: info-kibana
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      ELASTICSEARCH_USERNAME: ""
      ELASTICSEARCH_PASSWORD: ""
      XPACK_SECURITY_ENABLED: false
    ports:
      - "5601:5601"
    networks:
      - info-net
    depends_on:
      - elasticsearch
    restart: unless-stopped
    volumes:
      - ./config/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml

networks:
  info-net:
    external: true
```

#### 3.2 Metabaseæ•°æ®åˆ†æ
åˆ›å»º `docker-compose.metabase.yml`:
```yaml
version: '3.8'

services:
  metabase:
    image: metabase/metabase:latest
    container_name: info-metabase
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabase_db
      MB_DB_PORT: 5432
      MB_DB_USER: info_user
      MB_DB_PASS: your_secure_password
      MB_DB_HOST: postgres
    ports:
      - "3001:3000"
    networks:
      - info-net
    depends_on:
      - postgres
    restart: unless-stopped
    volumes:
      - ./data/metabase:/metabase-data

networks:
  info-net:
    external: true
```

### ç¬¬å››æ­¥ï¼šåå‘ä»£ç†å’ŒSSLé…ç½®

#### 4.1 Nginxåå‘ä»£ç†
åˆ›å»º `docker-compose.nginx.yml`:
```yaml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    container_name: info-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./data/nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    networks:
      - info-net
    depends_on:
      - freshrss
      - outline
      - bookstack
      - wallabag
      - kibana
      - metabase
    restart: unless-stopped

networks:
  info-net:
    external: true
```

åˆ›å»ºNginxé…ç½®æ–‡ä»¶ `config/nginx/nginx.conf`:
```nginx
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;
    
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate auth;
    gzip_types text/plain text/css text/xml text/javascript 
               application/x-javascript application/xml+rss;
    
    include /etc/nginx/conf.d/*.conf;
}
```

åˆ›å»ºæœåŠ¡é…ç½® `config/nginx/conf.d/info-collection.conf`:
```nginx
# FreshRSS
server {
    listen 80;
    server_name rss.localhost rss.yourdomain.com;
    
    location / {
        proxy_pass http://freshrss:80;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# Outline
server {
    listen 80;
    server_name outline.localhost outline.yourdomain.com;
    
    location / {
        proxy_pass http://outline:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocketæ”¯æŒ
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}

# BookStack
server {
    listen 80;
    server_name docs.localhost docs.yourdomain.com;
    
    location / {
        proxy_pass http://bookstack:80;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# Wallabag
server {
    listen 80;
    server_name read.localhost read.yourdomain.com;
    
    location / {
        proxy_pass http://wallabag:80;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# Kibana
server {
    listen 80;
    server_name kibana.localhost kibana.yourdomain.com;
    
    location / {
        proxy_pass http://kibana:5601;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# Metabase
server {
    listen 80;
    server_name analytics.localhost analytics.yourdomain.com;
    
    location / {
        proxy_pass http://metabase:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### ç¬¬äº”æ­¥ï¼šä¸€é”®éƒ¨ç½²è„šæœ¬

#### 5.1 ä¸»éƒ¨ç½²è„šæœ¬
åˆ›å»º `deploy.sh`:
```bash
#!/bin/bash

# ä¿¡æ¯æ”¶é›†ç³»ç»Ÿéƒ¨ç½²è„šæœ¬
set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½²ä¿¡æ¯æ”¶é›†æ•´ç†ç³»ç»Ÿ..."

# æ£€æŸ¥Dockerå’ŒDocker Compose
command -v docker >/dev/null 2>&1 || { echo "âŒ Dockeræœªå®‰è£…"; exit 1; }
command -v docker-compose >/dev/null 2>&1 || { echo "âŒ Docker Composeæœªå®‰è£…"; exit 1; }

# åˆ›å»ºç½‘ç»œ
echo "ğŸ“¡ åˆ›å»ºDockerç½‘ç»œ..."
docker network create info-net 2>/dev/null || echo "ç½‘ç»œå·²å­˜åœ¨"

# åˆå§‹åŒ–æ•°æ®åº“
echo "ğŸ—„ï¸ åˆå§‹åŒ–æ•°æ®åº“..."
cat > config/postgres/01-init-databases.sql << EOF
-- åˆ›å»ºå„ä¸ªåº”ç”¨çš„æ•°æ®åº“
CREATE DATABASE outline_db;
CREATE DATABASE bookstack_db;
CREATE DATABASE wallabag_db;
CREATE DATABASE metabase_db;

-- æˆæƒç”¨æˆ·è®¿é—®
GRANT ALL PRIVILEGES ON DATABASE outline_db TO info_user;
GRANT ALL PRIVILEGES ON DATABASE bookstack_db TO info_user;
GRANT ALL PRIVILEGES ON DATABASE wallabag_db TO info_user;
GRANT ALL PRIVILEGES ON DATABASE metabase_db TO info_user;
EOF

# æŒ‰é¡ºåºå¯åŠ¨æœåŠ¡
echo "ğŸ”§ å¯åŠ¨åŸºç¡€æœåŠ¡..."
docker-compose -f docker-compose.base.yml up -d

echo "â³ ç­‰å¾…æ•°æ®åº“å°±ç»ª..."
sleep 30

echo "ğŸ“š å¯åŠ¨ä¿¡æ¯æ”¶é›†å·¥å…·..."
docker-compose -f docker-compose.freshrss.yml up -d
docker-compose -f docker-compose.outline.yml up -d
docker-compose -f docker-compose.bookstack.yml up -d
docker-compose -f docker-compose.wallabag.yml up -d

echo "ğŸ“Š å¯åŠ¨åˆ†æå·¥å…·..."
docker-compose -f docker-compose.kibana.yml up -d
docker-compose -f docker-compose.metabase.yml up -d

echo "ğŸŒ å¯åŠ¨åå‘ä»£ç†..."
docker-compose -f docker-compose.nginx.yml up -d

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ğŸ¯ è®¿é—®åœ°å€ï¼š"
echo "ğŸ“° RSSèšåˆå™¨: http://rss.localhost"
echo "ğŸ“ çŸ¥è¯†åº“: http://outline.localhost"
echo "ğŸ“– æ–‡æ¡£å¹³å°: http://docs.localhost"
echo "ğŸ”– ç¨åé˜…è¯»: http://read.localhost"
echo "ğŸ“ˆ æ•°æ®å¯è§†åŒ–: http://kibana.localhost"
echo "ğŸ“Š æ•°æ®åˆ†æ: http://analytics.localhost"
echo ""
echo "ğŸ“‹ æŸ¥çœ‹æœåŠ¡çŠ¶æ€: docker-compose ps"
echo "ğŸ“œ æŸ¥çœ‹æ—¥å¿—: docker-compose logs -f [service_name]"
```

#### 5.2 é…ç½®hostsæ–‡ä»¶ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
```bash
# æ·»åŠ åˆ° /etc/hosts (Linux/Mac) æˆ– C:\Windows\System32\drivers\etc\hosts (Windows)
127.0.0.1 rss.localhost
127.0.0.1 outline.localhost
127.0.0.1 docs.localhost
127.0.0.1 read.localhost
127.0.0.1 kibana.localhost
127.0.0.1 analytics.localhost
```

### ç¬¬å…­æ­¥ï¼šé«˜çº§é…ç½®

#### 6.1 å…¨æ–‡æœç´¢é›†æˆ
åˆ›å»º `scripts/setup-elasticsearch-integration.sh`:
```bash
#!/bin/bash

# é…ç½®Elasticsearchç´¢å¼•æ¨¡æ¿
curl -X PUT "localhost:9200/_index_template/info-collection" \
-H 'Content-Type: application/json' \
-d '{
  "index_patterns": ["info-*"],
  "template": {
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 0,
      "analysis": {
        "analyzer": {
          "chinese_analyzer": {
            "type": "custom",
            "tokenizer": "ik_max_word",
            "filter": ["lowercase"]
          }
        }
      }
    },
    "mappings": {
      "properties": {
        "title": {
          "type": "text",
          "analyzer": "chinese_analyzer"
        },
        "content": {
          "type": "text",
          "analyzer": "chinese_analyzer"
        },
        "tags": {
          "type": "keyword"
        },
        "created_at": {
          "type": "date"
        },
        "source": {
          "type": "keyword"
        }
      }
    }
  }
}'

echo "Elasticsearchç´¢å¼•æ¨¡æ¿åˆ›å»ºå®Œæˆ"
```

#### 6.2 æ•°æ®åŒæ­¥è„šæœ¬
åˆ›å»º `scripts/sync-data.py`:
```python
#!/usr/bin/env python3
"""
ä¿¡æ¯æ”¶é›†ç³»ç»Ÿæ•°æ®åŒæ­¥è„šæœ¬
åŒæ­¥å„ä¸ªå·¥å…·çš„æ•°æ®åˆ°Elasticsearchè¿›è¡Œç»Ÿä¸€æœç´¢
"""

import requests
import json
import psycopg2
from elasticsearch import Elasticsearch
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class InfoCollectionSync:
    def __init__(self):
        self.es = Elasticsearch([{'host': 'localhost', 'port': 9200}])
        self.db_config = {
            'host': 'localhost',
            'port': 5432,
            'user': 'info_user',
            'password': 'your_secure_password'
        }
    
    def sync_freshrss_articles(self):
        """åŒæ­¥FreshRSSæ–‡ç« åˆ°Elasticsearch"""
        try:
            # è¿æ¥FreshRSSæ•°æ®åº“
            conn = psycopg2.connect(database='freshrss', **self.db_config)
            cursor = conn.cursor()
            
            # æŸ¥è¯¢æœ€æ–°æ–‡ç« 
            cursor.execute("""
                SELECT id, title, content, link, date_published, tags
                FROM articles 
                WHERE date_published > NOW() - INTERVAL '7 days'
            """)
            
            articles = cursor.fetchall()
            
            for article in articles:
                doc = {
                    'title': article[1],
                    'content': article[2],
                    'url': article[3],
                    'created_at': article[4],
                    'tags': article[5].split(',') if article[5] else [],
                    'source': 'freshrss'
                }
                
                self.es.index(
                    index=f"info-freshrss-{datetime.now().strftime('%Y-%m')}",
                    body=doc
                )
            
            logger.info(f"åŒæ­¥äº† {len(articles)} ç¯‡FreshRSSæ–‡ç« ")
            
        except Exception as e:
            logger.error(f"FreshRSSåŒæ­¥å¤±è´¥: {e}")
        finally:
            if 'conn' in locals():
                conn.close()
    
    def sync_outline_documents(self):
        """åŒæ­¥Outlineæ–‡æ¡£åˆ°Elasticsearch"""
        try:
            # ä½¿ç”¨Outline API
            headers = {'Authorization': 'Bearer YOUR_OUTLINE_API_TOKEN'}
            response = requests.get(
                'http://localhost:8081/api/documents.list',
                headers=headers
            )
            
            if response.status_code == 200:
                documents = response.json()['data']
                
                for doc in documents:
                    es_doc = {
                        'title': doc['title'],
                        'content': doc['text'],
                        'url': doc['url'],
                        'created_at': doc['createdAt'],
                        'tags': doc.get('tags', []),
                        'source': 'outline'
                    }
                    
                    self.es.index(
                        index=f"info-outline-{datetime.now().strftime('%Y-%m')}",
                        body=es_doc
                    )
                
                logger.info(f"åŒæ­¥äº† {len(documents)} ä¸ªOutlineæ–‡æ¡£")
            
        except Exception as e:
            logger.error(f"OutlineåŒæ­¥å¤±è´¥: {e}")
    
    def sync_wallabag_articles(self):
        """åŒæ­¥Wallabagæ–‡ç« åˆ°Elasticsearch"""
        try:
            conn = psycopg2.connect(database='wallabag_db', **self.db_config)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT title, content, url, created_at, is_starred
                FROM entry 
                WHERE created_at > NOW() - INTERVAL '7 days'
            """)
            
            articles = cursor.fetchall()
            
            for article in articles:
                doc = {
                    'title': article[0],
                    'content': article[1],
                    'url': article[2],
                    'created_at': article[3],
                    'is_starred': article[4],
                    'source': 'wallabag'
                }
                
                self.es.index(
                    index=f"info-wallabag-{datetime.now().strftime('%Y-%m')}",
                    body=doc
                )
            
            logger.info(f"åŒæ­¥äº† {len(articles)} ç¯‡Wallabagæ–‡ç« ")
            
        except Exception as e:
            logger.error(f"WallabagåŒæ­¥å¤±è´¥: {e}")
        finally:
            if 'conn' in locals():
                conn.close()

if __name__ == "__main__":
    sync = InfoCollectionSync()
    sync.sync_freshrss_articles()
    sync.sync_outline_documents()
    sync.sync_wallabag_articles()
```

#### 6.3 å®šæ—¶ä»»åŠ¡é…ç½®
åˆ›å»º `docker-compose.cron.yml`:
```yaml
version: '3.8'

services:
  cron-jobs:
    image: alpine:latest
    container_name: info-cron
    volumes:
      - ./scripts:/scripts
      - ./logs:/logs
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - info-net
    command: >
      sh -c "
        apk add --no-cache python3 py3-pip dcron &&
        pip3 install requests psycopg2-binary elasticsearch &&
        echo '0 */6 * * * cd /scripts && python3 sync-data.py >> /logs/sync.log 2>&1' | crontab - &&
        echo '0 2 * * * cd /scripts && ./backup.sh >> /logs/backup.log 2>&1' | crontab - &&
        crond -f
      "
    restart: unless-stopped

networks:
  info-net:
    external: true
```

## é«˜çº§é…ç½®

### SSL/TLSé…ç½®
ä½¿ç”¨Let's Encryptè‡ªåŠ¨è·å–SSLè¯ä¹¦ï¼š

```yaml
# docker-compose.ssl.yml
version: '3.8'

services:
  certbot:
    image: certbot/certbot
    container_name: info-certbot
    volumes:
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
    command: certonly --webroot --webroot-path=/var/www/certbot --email your-email@domain.com --agree-tos --no-eff-email -d yourdomain.com
    networks:
      - info-net

networks:
  info-net:
    external: true
```

### ç›‘æ§å’Œå‘Šè­¦
é›†æˆPrometheuså’ŒGrafanaï¼š

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: info-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - info-net
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: info-grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana:/etc/grafana/provisioning
    networks:
      - info-net
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:

networks:
  info-net:
    external: true
```

## ä½¿ç”¨æ–¹æ³•

### åˆå§‹é…ç½®æ­¥éª¤

#### 1. FreshRSSè®¾ç½®
1. è®¿é—® `http://rss.localhost`
2. åˆ›å»ºç®¡ç†å‘˜è´¦æˆ·
3. æ·»åŠ RSSè®¢é˜…æº
4. é…ç½®è‡ªåŠ¨æ›´æ–°é—´éš”
5. è®¾ç½®åˆ†ç±»å’Œæ ‡ç­¾

#### 2. Outlineé…ç½®
1. è®¿é—® `http://outline.localhost`
2. åˆ›å»ºå›¢é˜Ÿå’Œç”¨æˆ·è´¦æˆ·
3. å¯¼å…¥å·²æœ‰æ–‡æ¡£æˆ–åˆ›å»ºæ–°æ–‡æ¡£
4. è®¾ç½®æ–‡æ¡£ç»“æ„å’Œæƒé™

#### 3. BookStackè®¾ç½®
1. è®¿é—® `http://docs.localhost`
2. ä½¿ç”¨é»˜è®¤è´¦æˆ·ç™»å½• (admin@admin.com / password)
3. åˆ›å»ºä¹¦ç±å’Œç« èŠ‚ç»“æ„
4. é…ç½®ç”¨æˆ·æƒé™å’Œè§’è‰²

#### 4. Wallabagé…ç½®
1. è®¿é—® `http://read.localhost`
2. åˆ›å»ºç”¨æˆ·è´¦æˆ·
3. å®‰è£…æµè§ˆå™¨æ‰©å±•
4. é…ç½®ç§»åŠ¨åº”ç”¨

### å·¥ä½œæµç¨‹ç¤ºä¾‹

#### ä¿¡æ¯æ”¶é›†å·¥ä½œæµ
```
1. å‘ç°ä¿¡æ¯æº
   â”œâ”€â”€ RSSè®¢é˜… â†’ FreshRSS
   â”œâ”€â”€ ç½‘é¡µæ–‡ç«  â†’ Wallabag
   â””â”€â”€ å³æ—¶æƒ³æ³• â†’ Outline

2. ä¿¡æ¯å¤„ç†
   â”œâ”€â”€ é˜…è¯»å’Œæ ‡è®° â†’ Wallabag
   â”œâ”€â”€ æå–è¦ç‚¹ â†’ Outline
   â””â”€â”€ ç»“æ„åŒ–æ•´ç† â†’ BookStack

3. çŸ¥è¯†åº”ç”¨
   â”œâ”€â”€ æœç´¢æŸ¥æ‰¾ â†’ Elasticsearch
   â”œâ”€â”€ æ•°æ®åˆ†æ â†’ Metabase
   â””â”€â”€ å¯è§†åŒ–å±•ç¤º â†’ Kibana
```

#### å›¢é˜Ÿåä½œæµç¨‹
```
1. ä¿¡æ¯å…±äº«
   â”œâ”€â”€ å›¢é˜ŸRSSæº â†’ FreshRSS
   â”œâ”€â”€ å…±äº«çŸ¥è¯†åº“ â†’ Outline
   â””â”€â”€ é¡¹ç›®æ–‡æ¡£ â†’ BookStack

2. åä½œç¼–è¾‘
   â”œâ”€â”€ å®æ—¶ç¼–è¾‘ â†’ Outline
   â”œâ”€â”€ ç‰ˆæœ¬æ§åˆ¶ â†’ BookStack
   â””â”€â”€ è¯„è®ºè®¨è®º â†’ å„å¹³å°

3. çŸ¥è¯†ç®¡ç†
   â”œâ”€â”€ åˆ†ç±»æ•´ç† â†’ æ ‡ç­¾ç³»ç»Ÿ
   â”œâ”€â”€ æƒé™æ§åˆ¶ â†’ ç”¨æˆ·ç®¡ç†
   â””â”€â”€ æ•°æ®å¤‡ä»½ â†’ è‡ªåŠ¨å¤‡ä»½
```

## ç»´æŠ¤å’Œå¤‡ä»½

### è‡ªåŠ¨å¤‡ä»½è„šæœ¬
åˆ›å»º `scripts/backup.sh`:
```bash
#!/bin/bash

# ä¿¡æ¯æ”¶é›†ç³»ç»Ÿå¤‡ä»½è„šæœ¬
BACKUP_DIR="/backups/info-collection-$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "ğŸ—„ï¸ å¼€å§‹å¤‡ä»½æ•°æ®åº“..."

# å¤‡ä»½PostgreSQLæ•°æ®åº“
docker exec info-postgres pg_dumpall -U info_user > "$BACKUP_DIR/postgres_backup.sql"

# å¤‡ä»½Redisæ•°æ®
docker exec info-redis redis-cli --rdb /tmp/dump.rdb
docker cp info-redis:/tmp/dump.rdb "$BACKUP_DIR/redis_backup.rdb"

# å¤‡ä»½Elasticsearchæ•°æ®
curl -X POST "localhost:9200/_snapshot/backup_repo/snapshot_$(date +%Y%m%d_%H%M%S)?wait_for_completion=true"

echo "ğŸ“ å¤‡ä»½åº”ç”¨æ•°æ®..."

# å¤‡ä»½åº”ç”¨æ•°æ®ç›®å½•
tar -czf "$BACKUP_DIR/app_data.tar.gz" ./data/

# å¤‡ä»½é…ç½®æ–‡ä»¶
tar -czf "$BACKUP_DIR/configs.tar.gz" ./config/

echo "ğŸ§¹ æ¸…ç†è€å¤‡ä»½..."
find /backups -type d -mtime +30 -name "info-collection-*" -exec rm -rf {} +

echo "âœ… å¤‡ä»½å®Œæˆ: $BACKUP_DIR"
```

### æ¢å¤è„šæœ¬
åˆ›å»º `scripts/restore.sh`:
```bash
#!/bin/bash

if [ -z "$1" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <backup_directory>"
    exit 1
fi

BACKUP_DIR=$1

echo "ğŸ”„ å¼€å§‹æ¢å¤æ•°æ®..."

# åœæ­¢æ‰€æœ‰æœåŠ¡
docker-compose down

# æ¢å¤PostgreSQL
if [ -f "$BACKUP_DIR/postgres_backup.sql" ]; then
    docker-compose -f docker-compose.base.yml up -d postgres
    sleep 30
    docker exec -i info-postgres psql -U info_user < "$BACKUP_DIR/postgres_backup.sql"
fi

# æ¢å¤Redis
if [ -f "$BACKUP_DIR/redis_backup.rdb" ]; then
    docker cp "$BACKUP_DIR/redis_backup.rdb" info-redis:/data/dump.rdb
fi

# æ¢å¤åº”ç”¨æ•°æ®
if [ -f "$BACKUP_DIR/app_data.tar.gz" ]; then
    tar -xzf "$BACKUP_DIR/app_data.tar.gz" -C ./
fi

# æ¢å¤é…ç½®æ–‡ä»¶
if [ -f "$BACKUP_DIR/configs.tar.gz" ]; then
    tar -xzf "$BACKUP_DIR/configs.tar.gz" -C ./
fi

# é‡æ–°å¯åŠ¨æ‰€æœ‰æœåŠ¡
./deploy.sh

echo "âœ… æ¢å¤å®Œæˆ"
```

### ç³»ç»Ÿç›‘æ§

#### å¥åº·æ£€æŸ¥è„šæœ¬
åˆ›å»º `scripts/health-check.sh`:
```bash
#!/bin/bash

# ç³»ç»Ÿå¥åº·æ£€æŸ¥è„šæœ¬

echo "ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥æŠ¥å‘Š"
echo "=========================="

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ“Š æœåŠ¡çŠ¶æ€ï¼š"
services=("info-postgres" "info-redis" "info-elasticsearch" "info-freshrss" "info-outline" "info-bookstack" "info-wallabag" "info-kibana" "info-metabase" "info-nginx")

for service in "${services[@]}"; do
    if docker ps --format "table {{.Names}}" | grep -q "$service"; then
        echo "âœ… $service: è¿è¡Œä¸­"
    else
        echo "âŒ $service: åœæ­¢"
    fi
done

# æ£€æŸ¥ç£ç›˜ç©ºé—´
echo ""
echo "ğŸ’¾ ç£ç›˜ç©ºé—´ï¼š"
df -h | grep -E "(/$|/data)" | while read line; do
    usage=$(echo $line | awk '{print $5}' | sed 's/%//')
    if [ $usage -gt 80 ]; then
        echo "âš ï¸  $line"
    else
        echo "âœ… $line"
    fi
done

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
echo ""
echo "ğŸ§  å†…å­˜ä½¿ç”¨ï¼š"
memory_usage=$(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100}')
if (( $(echo "$memory_usage > 80" | bc -l) )); then
    echo "âš ï¸  å†…å­˜ä½¿ç”¨ç‡: ${memory_usage}%"
else
    echo "âœ… å†…å­˜ä½¿ç”¨ç‡: ${memory_usage}%"
fi

# æ£€æŸ¥ç½‘ç»œè¿æ¥
echo ""
echo "ğŸŒ ç½‘ç»œè¿æ¥ï¼š"
endpoints=("http://localhost:8080" "http://localhost:8081" "http://localhost:8082" "http://localhost:8083" "http://localhost:5601" "http://localhost:3001")

for endpoint in "${endpoints[@]}"; do
    if curl -s --head "$endpoint" | head -n 1 | grep -q "HTTP/1.[01] [23].."; then
        echo "âœ… $endpoint: å¯è®¿é—®"
    else
        echo "âŒ $endpoint: ä¸å¯è®¿é—®"
    fi
done

echo ""
echo "ğŸ“… æ£€æŸ¥æ—¶é—´: $(date)"
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### 1. æ•°æ®åº“è¿æ¥å¤±è´¥
**ç—‡çŠ¶**: åº”ç”¨æ— æ³•è¿æ¥åˆ°PostgreSQL
**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker logs info-postgres

# é‡å¯æ•°æ®åº“
docker restart info-postgres

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker exec info-outline ping postgres
```

#### 2. Elasticsearchå†…å­˜ä¸è¶³
**ç—‡çŠ¶**: Elasticsearchå¯åŠ¨å¤±è´¥æˆ–æ€§èƒ½å·®
**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¢åŠ è™šæ‹Ÿå†…å­˜é™åˆ¶
sudo sysctl -w vm.max_map_count=262144

# è°ƒæ•´Elasticsearchå†…å­˜é…ç½®
# åœ¨docker-compose.base.ymlä¸­ä¿®æ”¹ES_JAVA_OPTS
```

#### 3. ç£ç›˜ç©ºé—´ä¸è¶³
**ç—‡çŠ¶**: å®¹å™¨å¯åŠ¨å¤±è´¥æˆ–æ•°æ®å†™å…¥é”™è¯¯
**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ¸…ç†Dockerç³»ç»Ÿ
docker system prune -a

# æ¸…ç†æ—¥å¿—æ–‡ä»¶
find ./logs -name "*.log" -mtime +7 -delete

# æ¸…ç†è€å¤‡ä»½
find ./backups -mtime +30 -delete
```

#### 4. æœåŠ¡ç«¯å£å†²çª
**ç—‡çŠ¶**: æœåŠ¡å¯åŠ¨æ—¶ç«¯å£å·²è¢«å ç”¨
**è§£å†³æ–¹æ¡ˆ**:
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
netstat -tulpn | grep :8080

# ä¿®æ”¹docker-composeæ–‡ä»¶ä¸­çš„ç«¯å£æ˜ å°„
# æˆ–åœæ­¢å ç”¨ç«¯å£çš„å…¶ä»–æœåŠ¡
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. æ•°æ®åº“ä¼˜åŒ–
```sql
-- PostgreSQLæ€§èƒ½è°ƒä¼˜
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET default_statistics_target = 100;
```

#### 2. Elasticsearchä¼˜åŒ–
```yaml
# elasticsearch.yml
cluster.name: "info-collection"
node.name: "info-node-1"
path.data: /usr/share/elasticsearch/data
path.logs: /usr/share/elasticsearch/logs
bootstrap.memory_lock: true
network.host: 0.0.0.0
http.port: 9200
discovery.type: single-node

# JVMé€‰é¡¹ä¼˜åŒ–
ES_JAVA_OPTS: "-Xms2g -Xmx2g -XX:+UseG1GC"
```

#### 3. Redisä¼˜åŒ–
```conf
# redis.conf
maxmemory 512mb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
```

### æ—¥å¿—ç®¡ç†

#### é›†ä¸­æ—¥å¿—æ”¶é›†
åˆ›å»º `docker-compose.logging.yml`:
```yaml
version: '3.8'

services:
  fluentd:
    image: fluent/fluentd:v1.16-debian-1
    container_name: info-fluentd
    volumes:
      - ./config/fluentd:/fluentd/etc
      - ./logs:/var/log
    ports:
      - "24224:24224"
    networks:
      - info-net
    restart: unless-stopped

networks:
  info-net:
    external: true
```

#### æ—¥å¿—åˆ†æé…ç½®
åˆ›å»º `config/fluentd/fluent.conf`:
```xml
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<match nginx.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name nginx-logs
  type_name _doc
</match>

<match app.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name app-logs
  type_name _doc
</match>

<match **>
  @type stdout
</match>
```

## æ‰©å±•å’Œå®šåˆ¶

### æ·»åŠ æ–°çš„ä¿¡æ¯æ”¶é›†å·¥å…·

#### ç¤ºä¾‹ï¼šé›†æˆMiniflux RSSé˜…è¯»å™¨
```yaml
# docker-compose.miniflux.yml
version: '3.8'

services:
  miniflux:
    image: miniflux/miniflux:latest
    container_name: info-miniflux
    environment:
      DATABASE_URL: postgres://info_user:your_secure_password@postgres:5432/miniflux_db?sslmode=disable
      RUN_MIGRATIONS: 1
      CREATE_ADMIN: 1
      ADMIN_USERNAME: admin
      ADMIN_PASSWORD: admin123
    ports:
      - "8084:8080"
    networks:
      - info-net
    depends_on:
      - postgres
    restart: unless-stopped

networks:
  info-net:
    external: true
```

### APIé›†æˆç¤ºä¾‹

#### Webhookæ¥æ”¶å™¨
åˆ›å»º `services/webhook-receiver.py`:
```python
from flask import Flask, request, jsonify
import json
from elasticsearch import Elasticsearch

app = Flask(__name__)
es = Elasticsearch([{'host': 'localhost', 'port': 9200}])

@app.route('/webhook/freshrss', methods=['POST'])
def freshrss_webhook():
    """æ¥æ”¶FreshRSSçš„æ–°æ–‡ç« é€šçŸ¥"""
    data = request.json
    
    # å¤„ç†æ•°æ®å¹¶ç´¢å¼•åˆ°Elasticsearch
    doc = {
        'title': data.get('title'),
        'content': data.get('content'),
        'url': data.get('link'),
        'source': 'freshrss-webhook',
        'timestamp': data.get('date_published')
    }
    
    es.index(index='info-realtime', body=doc)
    
    return jsonify({'status': 'success'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## æ€»ç»“

è¿™ä¸ªåŸºäºDockerçš„ä¿¡æ¯æ”¶é›†æ•´ç†ç³»ç»Ÿæä¾›äº†ï¼š

1. **å®Œæ•´çš„å·¥å…·é“¾**: RSSèšåˆã€çŸ¥è¯†ç®¡ç†ã€æ–‡æ¡£å¹³å°ã€ç¨åé˜…è¯»
2. **ç»Ÿä¸€çš„æœç´¢**: Elasticsearchå…¨æ–‡æœç´¢å’Œæ•°æ®åˆ†æ
3. **å®¹å™¨åŒ–éƒ¨ç½²**: ä¸€é”®éƒ¨ç½²ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
4. **æ•°æ®å¤‡ä»½**: è‡ªåŠ¨å¤‡ä»½å’Œæ¢å¤æœºåˆ¶
5. **ç›‘æ§å‘Šè­¦**: å¥åº·æ£€æŸ¥å’Œæ€§èƒ½ç›‘æ§
6. **å¯æ‰©å±•æ€§**: æ˜“äºæ·»åŠ æ–°å·¥å…·å’ŒåŠŸèƒ½

é€šè¿‡è¿™å¥—ç³»ç»Ÿï¼Œæ‚¨å¯ä»¥æ„å»ºä¸€ä¸ªé«˜æ•ˆçš„ä¸ªäººæˆ–å›¢é˜Ÿä¿¡æ¯æ”¶é›†æ•´ç†å¹³å°ï¼Œæå‡çŸ¥è¯†ç®¡ç†æ•ˆç‡ã€‚